{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14db562-5431-4f46-8ee7-ae2ef30b0e11",
   "metadata": {},
   "source": [
    "### DDTCDR VS SVD\n",
    "This notebook is for validting the generality of the DDTCDR model.\n",
    "- We use the original code and partial dataset publish on [github.com](https://github.com/lpworld/DDTCDR)\n",
    "- The train test split we keep identical to the original code\n",
    "- The evluation is the same as the original paper: MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc57ed-46e0-4a1a-a5b8-ed854b0a74b6",
   "metadata": {},
   "source": [
    "### 1. Import Libs and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2030f758-f2b5-4815-bea2-03722871a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680912f1-c0a6-457c-8802-ae44683b2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = pd.read_csv('../DDTCDR/book.csv')\n",
    "movie = pd.read_csv('../DDTCDR/movie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ad070-73b5-46ee-b712-af3372e36772",
   "metadata": {},
   "source": [
    "### 2. Rating normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5be358e-8504-4f4a-9022-9eeced11ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ratings):\n",
    "    \"\"\"normalize into [0, 1] from [0, max_rating]\"\"\"\n",
    "    ratings = deepcopy(ratings)\n",
    "    max_rating = ratings.rating.max()\n",
    "    ratings['rating'] = ratings.rating * 1.0 / max_rating\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27e8ac3-3704-43fa-b910-f0384e46132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = normalize(book)\n",
    "movie = normalize(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf42f32-34df-4cdc-a31f-3f85e032557d",
   "metadata": {},
   "source": [
    "### 3. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630db63b-9324-4211-9dea-8b4269c7a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 4 * len(book) // 5\n",
    "train_book = book[:cut]\n",
    "test_book = book[cut:]\n",
    "\n",
    "cut_movie = 4 * len(movie) // 5\n",
    "train_movie = movie[:cut_movie]\n",
    "test_movie = movie[cut_movie:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdac619-2a7c-4c40-8120-b267171109b7",
   "metadata": {},
   "source": [
    "### 4.1 Use SVD on training Movie data and evluate on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a691df5d-23ec-4c91-989a-fcdc0771967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise import accuracy\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538b1d88-25db-43b2-8a1c-7d549c064a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    }
   ],
   "source": [
    "my_seed = 13\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "training_data = Dataset.load_from_df(train_movie[['userId', 'itemId', 'rating']], reader)\n",
    "testing_data = Dataset.load_from_df(test_movie[['userId', 'itemId', 'rating']], reader)\n",
    "algo = SVD(verbose = True, n_factors = 10)\n",
    "training_data = training_data.build_full_trainset()\n",
    "testing_data = testing_data.build_full_trainset().build_testset()\n",
    "\n",
    "algo.fit(training_data,)\n",
    "training_eval = training_data.build_testset()\n",
    "train_pre = algo.test(training_eval)\n",
    "train_mae = accuracy.mae(train_pre, verbose=False)\n",
    "test_pre = algo.test(testing_data)\n",
    "test_mae = accuracy.mae(test_pre, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517db2b6-0271-41c8-a4b8-7d72fe48b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only using in-domain movie data on SVD: 0.147\n"
     ]
    }
   ],
   "source": [
    "print(f\"The only using in-domain movie data on SVD: {round(test_mae, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28abe05-0d0b-4c5d-a557-c8cdd7792570",
   "metadata": {},
   "source": [
    "### 4.2 Use SVD on training Book data and evluate on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b017d71-4d15-45c1-96c6-2ef6062f28fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    }
   ],
   "source": [
    "my_seed = 13\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "reader = Reader(rating_scale=(0,1))\n",
    "training_data = Dataset.load_from_df(train_book[['userId', 'itemId', 'rating']], reader)\n",
    "testing_data = Dataset.load_from_df(test_book[['userId', 'itemId', 'rating']], reader)\n",
    "algo = SVD(verbose = True, n_factors = 10)\n",
    "training_data = training_data.build_full_trainset()\n",
    "testing_data = testing_data.build_full_trainset().build_testset()\n",
    "\n",
    "algo.fit(training_data,)\n",
    "training_eval = training_data.build_testset()\n",
    "train_pre = algo.test(training_eval)\n",
    "train_mae = accuracy.mae(train_pre, verbose=False)\n",
    "test_pre = algo.test(testing_data)\n",
    "test_mae = accuracy.mae(test_pre, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89d2741-7857-48ec-8657-1a28f5e00621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The only using in-domain book data on SVD: 0.13\n"
     ]
    }
   ],
   "source": [
    "print(f\"The only using in-domain book data on SVD: {round(test_mae, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
